{"cells":[{"cell_type":"markdown","metadata":{"_uuid":"31aff975d245f351c6a47a411251c09cf0df142a","colab_type":"text","id":"RPIBkis9u_2Q"},"source":["# Alzheimers Prediction on oasis dataset"]},{"cell_type":"code","execution_count":1,"metadata":{"_uuid":"6a720755860b07d7eb93e458306ec1b6fa079ed5"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","sns.set()\n","\n","df = pd.read_csv('../input/oasis_longitudinal.csv')\n","df.head()"]},{"cell_type":"code","execution_count":2,"metadata":{"_uuid":"08991ab4c6c3aef89ad366662aad97a846aa9d8f","collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"source":["df = df.loc[df['Visit']==1] # use first visit data only because of the analysis we're doing\n","df = df.reset_index(drop=True) # reset index after filtering first visit data\n","df['M/F'] = df['M/F'].replace(['F','M'], [0,1]) # M/F column\n","df['Group'] = df['Group'].replace(['Converted'], ['Demented']) # Target variable\n","df['Group'] = df['Group'].replace(['Demented', 'Nondemented'], [1,0]) # Target variable\n","df = df.drop(['MRI ID', 'Visit', 'Hand'], axis=1) # Drop unnecessary columns"]},{"cell_type":"code","execution_count":3,"metadata":{"_uuid":"9175b97a0b02ff8ace2e3bc8a6327488b3232783","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":919,"output_extras":[{"item_id":1}]},"colab_type":"code","collapsed":true,"executionInfo":{"elapsed":11761,"status":"error","timestamp":1512599691671,"user":{"displayName":"Saurin Parikh","photoUrl":"//lh3.googleusercontent.com/-6RG-0wrBKjU/AAAAAAAAAAI/AAAAAAAABpU/h5Zwf5zd3tk/s50-c-k-no/photo.jpg","userId":"104703813675171986785"},"user_tz":300},"id":"-4-ZVrHJslSF","jupyter":{"outputs_hidden":true},"outputId":"5f5cc170-02d6-41d4-f5f2-3b575833b56b"},"outputs":[],"source":["# bar drawing function\n","def bar_chart(feature):\n","    Demented = df[df['Group']==1][feature].value_counts()\n","    Nondemented = df[df['Group']==0][feature].value_counts()\n","    df_bar = pd.DataFrame([Demented,Nondemented])\n","    df_bar.index = ['Demented','Nondemented']\n","    df_bar.plot(kind='bar',stacked=True, figsize=(8,5))"]},{"cell_type":"code","execution_count":4,"metadata":{"_uuid":"5f8599d4f70b78047011217e3bbcaa26311fddc6","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{},{}]},"colab_type":"code","id":"k-92eJ7pslSL","outputId":"d9940867-44f6-4d3a-f6fb-ddef5630877e"},"outputs":[],"source":["# Gender  and  Group ( Femal=0, Male=1)\n","bar_chart('M/F')\n","plt.xlabel('Group')\n","plt.ylabel('Number of patients')\n","plt.legend()\n","plt.title('Gender and Demented rate')"]},{"cell_type":"code","execution_count":5,"metadata":{"_uuid":"e1b8fbe86bbf469971aed915c2b8e9caa9cdbe53","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{},{}]},"colab_type":"code","id":"QfZMuTl7slSP","outputId":"b3a6a8a7-5cd6-48eb-e631-20b8d30c3bad"},"outputs":[],"source":["#MMSE : Mini Mental State Examination\n","# Nondemented = 0, Demented =1\n","# Nondemented has higher test result ranging from 25 to 30. \n","#Min 17 ,MAX 30\n","facet= sns.FacetGrid(df,hue=\"Group\", aspect=3)\n","facet.map(sns.kdeplot,'MMSE',shade= True)\n","facet.set(xlim=(0, df['MMSE'].max()))\n","facet.add_legend()\n","plt.xlim(15.30)"]},{"cell_type":"code","execution_count":6,"metadata":{"_uuid":"4dc483b489417595af5d23cf7a44de13c8ba371d","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{},{},{},{}]},"colab_type":"code","id":"JPuWkiWGslSS","outputId":"4088e3c2-8493-41d2-c61a-c386e784fd37"},"outputs":[],"source":["#bar_chart('ASF') = Atlas Scaling Factor\n","facet= sns.FacetGrid(df,hue=\"Group\", aspect=3)\n","facet.map(sns.kdeplot,'ASF',shade= True)\n","facet.set(xlim=(0, df['ASF'].max()))\n","facet.add_legend()\n","plt.xlim(0.5, 2)\n","\n","#eTIV = Estimated Total Intracranial Volume\n","facet= sns.FacetGrid(df,hue=\"Group\", aspect=3)\n","facet.map(sns.kdeplot,'eTIV',shade= True)\n","facet.set(xlim=(0, df['eTIV'].max()))\n","facet.add_legend()\n","plt.xlim(900, 2100)\n","\n","#'nWBV' = Normalized Whole Brain Volume\n","# Nondemented = 0, Demented =1\n","facet= sns.FacetGrid(df,hue=\"Group\", aspect=3)\n","facet.map(sns.kdeplot,'nWBV',shade= True)\n","facet.set(xlim=(0, df['nWBV'].max()))\n","facet.add_legend()\n","plt.xlim(0.6,0.9)"]},{"cell_type":"code","execution_count":7,"metadata":{"_uuid":"87a846e38f21e28b3c7ad6bae536b7cd2c3e2466","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{},{}]},"colab_type":"code","id":"w6rN7jjSslSW","outputId":"fbb23e63-a926-477c-c6ff-fc87933c1ea6"},"outputs":[],"source":["#AGE. Nondemented =0, Demented =0\n","facet= sns.FacetGrid(df,hue=\"Group\", aspect=3)\n","facet.map(sns.kdeplot,'Age',shade= True)\n","facet.set(xlim=(0, df['Age'].max()))\n","facet.add_legend()\n","plt.xlim(50,100)"]},{"cell_type":"code","execution_count":8,"metadata":{"_uuid":"8177a32eff0fece26f2220ccc046843347afc41e","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{},{}]},"colab_type":"code","id":"w6rN7jjSslSW","outputId":"fbb23e63-a926-477c-c6ff-fc87933c1ea6"},"outputs":[],"source":["#'EDUC' = Years of Education\n","# Nondemented = 0, Demented =1\n","facet= sns.FacetGrid(df,hue=\"Group\", aspect=3)\n","facet.map(sns.kdeplot,'EDUC',shade= True)\n","facet.set(xlim=(df['EDUC'].min(), df['EDUC'].max()))\n","facet.add_legend()\n","plt.ylim(0, 0.16)"]},{"cell_type":"markdown","metadata":{"_uuid":"80a9f0ebb50abd31cfa14ed7d93204d00f313543","colab_type":"text","id":"dR7e2FEuScR8"},"source":["# Data Preprocessing"]},{"cell_type":"code","execution_count":9,"metadata":{"_uuid":"c485e9bdba313a2897fa58aa61406f07c2206c27","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{}]},"colab_type":"code","id":"crn5DxTUScSI","outputId":"10613858-0403-4c42-aea7-7bc3635ef60e"},"outputs":[],"source":["# Check missing values by each column\n","pd.isnull(df).sum() \n","# The column, SES has 8 missing values"]},{"cell_type":"markdown","metadata":{"_uuid":"10bb2143731149217bd59b8ea7fb2f12706dd355","colab_type":"text","id":"v96VUyPYScSL"},"source":["## Removing rows with missing values"]},{"cell_type":"code","execution_count":10,"metadata":{"_uuid":"71f15a1cda750ae72a718d2ec0aa7939ac2b7855","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{}]},"colab_type":"code","id":"NCuXVrJtScSM","outputId":"29e022db-bb16-44f6-bfc7-3cd3fbb6f930"},"outputs":[],"source":["# Dropped the 8 rows with missing values in the column, SES\n","df_dropna = df.dropna(axis=0, how='any')\n","pd.isnull(df_dropna).sum()"]},{"cell_type":"code","execution_count":11,"metadata":{"_uuid":"a08f0ff032efa883e45e9b5bd2b6d386dd89f9b3","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{}]},"colab_type":"code","id":"ThXMkCk0ScSQ","outputId":"24c17bc4-f411-470d-e483-cd6098eff679"},"outputs":[],"source":["df_dropna['Group'].value_counts()"]},{"cell_type":"markdown","metadata":{"_uuid":"9a81499adca6b212e798a6b9a123c5806d57e087","colab_type":"text","id":"A0ipe9qsScSU"},"source":["## Imputation\n"]},{"cell_type":"code","execution_count":12,"metadata":{"_uuid":"1c2354281b56aaac81b5dd09cee531be85a72b1f","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{}]},"colab_type":"code","id":"62IgZtwnScSV","outputId":"a5e8f86e-66d6-4147-83f7-f26b12787245"},"outputs":[],"source":["# Draw scatter plot between EDUC and SES\n","x = df['EDUC']\n","y = df['SES']\n","\n","ses_not_null_index = y[~y.isnull()].index\n","x = x[ses_not_null_index]\n","y = y[ses_not_null_index]\n","\n","# Draw trend line in red\n","z = np.polyfit(x, y, 1)\n","p = np.poly1d(z)\n","plt.plot(x, y, 'go', x, p(x), \"r--\")\n","plt.xlabel('Education Level(EDUC)')\n","plt.ylabel('Social Economic Status(SES)')\n","\n","plt.show()"]},{"cell_type":"code","execution_count":13,"metadata":{"_uuid":"d2fcc229a25ba9ad1097de001cd53505ad0ba478","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{}]},"colab_type":"code","id":"cKaMRSvgScSY","outputId":"f05f5530-b14c-4bb8-abbb-037e2a0838e3"},"outputs":[],"source":["df.groupby(['EDUC'])['SES'].median()"]},{"cell_type":"code","execution_count":14,"metadata":{"_uuid":"b41fdf3fc1f569f482e8a506f0737775e84b338a","colab":{"autoexec":{"startup":false,"wait_interval":0}},"colab_type":"code","collapsed":true,"id":"dj_edAcdScSb","jupyter":{"outputs_hidden":true}},"outputs":[],"source":["df[\"SES\"].fillna(df.groupby(\"EDUC\")[\"SES\"].transform(\"median\"), inplace=True)"]},{"cell_type":"code","execution_count":15,"metadata":{"_uuid":"63c36b7bc32f5cc65c8bf908113ba919a17fc5b8","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{}]},"colab_type":"code","id":"Y4SgUM58ScSd","outputId":"9325d3dc-7f01-4be2-a932-a39c68d202b7"},"outputs":[],"source":["# I confirm there're no more missing values and all the 150 data were used.\n","pd.isnull(df['SES']).value_counts()"]},{"cell_type":"markdown","metadata":{"_uuid":"61220f51b25e5efcc5ceaa0d8f133967514b33a5"},"source":["##  Splitting Train/Validation/Test Sets"]},{"cell_type":"code","execution_count":16,"metadata":{"_uuid":"b039c111537091add5e04716b4d33501855155e8","colab":{"autoexec":{"startup":false,"wait_interval":0}},"colab_type":"code","collapsed":true,"id":"kJcRjpOIScSj","jupyter":{"outputs_hidden":true}},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from sklearn import preprocessing\n","from sklearn.preprocessing import MinMaxScaler \n","from sklearn.model_selection import cross_val_score"]},{"cell_type":"code","execution_count":17,"metadata":{"_uuid":"9c0cd7fedabdd26e4dbd2e5ed19a79c9097511c8","colab":{"autoexec":{"startup":false,"wait_interval":0}},"colab_type":"code","collapsed":true,"id":"eI6EXWT7ScSm","jupyter":{"outputs_hidden":true}},"outputs":[],"source":["# Dataset with imputation\n","Y = df['Group'].values # Target for the model\n","X = df[['M/F', 'Age', 'EDUC', 'SES', 'MMSE', 'eTIV', 'nWBV', 'ASF']] # Features we use\n","\n","# splitting into three sets\n","X_trainval, X_test, Y_trainval, Y_test = train_test_split(\n","    X, Y, random_state=0)\n","\n","# Feature scaling\n","scaler = MinMaxScaler().fit(X_trainval)\n","X_trainval_scaled = scaler.transform(X_trainval)\n","X_test_scaled = scaler.transform(X_test)"]},{"cell_type":"code","execution_count":18,"metadata":{"_uuid":"aa47c091672863c3ad5c785a65cf227977cb9c37","colab":{"autoexec":{"startup":false,"wait_interval":0}},"colab_type":"code","collapsed":true,"id":"oQAwHijeScSq","jupyter":{"outputs_hidden":true}},"outputs":[],"source":["# Dataset after dropping missing value rows\n","Y = df_dropna['Group'].values # Target for the model\n","X = df_dropna[['M/F', 'Age', 'EDUC', 'SES', 'MMSE', 'eTIV', 'nWBV', 'ASF']] # Features we use\n","\n","# splitting into three sets\n","X_trainval_dna, X_test_dna, Y_trainval_dna, Y_test_dna = train_test_split(\n","    X, Y, random_state=0)\n","\n","# Feature scaling\n","scaler = MinMaxScaler().fit(X_trainval_dna)\n","X_trainval_scaled_dna = scaler.transform(X_trainval_dna)\n","X_test_scaled_dna = scaler.transform(X_test_dna)"]},{"cell_type":"markdown","metadata":{"_uuid":"b2356d2f3b9b746909c52e98c88c9dd9e20f77bf","colab_type":"text","id":"Hh0VrtWIScSt"},"source":["## Cross-validation"]},{"cell_type":"markdown","metadata":{"_uuid":"27d4266a859c95510a8355df6c98c741a4805224","colab_type":"text","id":"vgYxX0OkScSj"},"source":["#  MODEL"]},{"cell_type":"markdown","metadata":{"_uuid":"52d9efbf3184f96ff3a0767e08d3d1e6f8ea1a73","colab_type":"text","id":"L0zOT1CAScSu"},"source":["## Logistic Regression\n","The parameter C, inverse of regularization strength.\n","\n","Tuning range: [0.001, 0.1, 1, 10, 100]"]},{"cell_type":"code","execution_count":19,"metadata":{"_uuid":"f8dcc6798d6f0aa777fff85c880a47ec78ad9e5c","collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, roc_curve, auc"]},{"cell_type":"code","execution_count":20,"metadata":{"_uuid":"252a6294c3c8754c0e19660e5ad7c0af189fd8e5","colab":{"autoexec":{"startup":false,"wait_interval":0}},"colab_type":"code","collapsed":true,"id":"nvBhRVT_ScSu","jupyter":{"outputs_hidden":true}},"outputs":[],"source":["acc = [] # list to store all performance metric"]},{"cell_type":"code","execution_count":21,"metadata":{"_uuid":"cb9f7249fa6793ec6e339aeb9936c26fbdfe552d","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{}]},"colab_type":"code","id":"xsWC0JpIScSw","outputId":"f0c4357e-951e-4078-9356-f01f7326c056"},"outputs":[],"source":["# Dataset with imputation\n","best_score=0\n","kfolds=5 # set the number of folds\n","\n","for c in [0.001, 0.1, 1, 10, 100]:\n","    logRegModel = LogisticRegression(C=c)\n","    # perform cross-validation\n","    scores = cross_val_score(logRegModel, X_trainval, Y_trainval, cv=kfolds, scoring='accuracy') # Get recall for each parameter setting\n","    \n","    # compute mean cross-validation accuracy\n","    score = np.mean(scores)\n","    \n","    # Find the best parameters and score\n","    if score > best_score:\n","        best_score = score\n","        best_parameters = c\n","\n","# rebuild a model on the combined training and validation set\n","SelectedLogRegModel = LogisticRegression(C=best_parameters).fit(X_trainval_scaled, Y_trainval)\n","\n","test_score = SelectedLogRegModel.score(X_test_scaled, Y_test)\n","PredictedOutput = SelectedLogRegModel.predict(X_test_scaled)\n","test_recall = recall_score(Y_test, PredictedOutput, pos_label=1)\n","fpr, tpr, thresholds = roc_curve(Y_test, PredictedOutput, pos_label=1)\n","test_auc = auc(fpr, tpr)\n","print(\"Best accuracy on validation set is:\", best_score)\n","print(\"Best parameter for regularization (C) is: \", best_parameters)\n","print(\"Test accuracy with best C parameter is\", test_score)\n","print(\"Test recall with the best C parameter is\", test_recall)\n","print(\"Test AUC with the best C parameter is\", test_auc)\n","m = 'Logistic Regression (w/ imputation)'\n","acc.append([m, test_score, test_recall, test_auc, fpr, tpr, thresholds])"]},{"cell_type":"code","execution_count":22,"metadata":{"_uuid":"200d475f03c493ecc5de448537841771d0817eb9","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{}]},"colab_type":"code","id":"Zb-VqkXUScSz","outputId":"2f1858c0-335a-4720-dc18-bef6e3c10a9e"},"outputs":[],"source":["# Dataset after dropping missing value rows\n","best_score=0\n","kfolds=5 # set the number of folds\n","\n","for c in [0.001, 0.1, 1, 10, 100]:\n","    logRegModel = LogisticRegression(C=c)\n","    # perform cross-validation\n","    scores = cross_val_score(logRegModel, X_trainval_scaled_dna, Y_trainval_dna, cv=kfolds, scoring='accuracy')\n","    \n","    # compute mean cross-validation accuracy\n","    score = np.mean(scores)\n","    \n","    # Find the best parameters and score\n","    if score > best_score:\n","        best_score = score\n","        best_parameters = c\n","\n","# rebuild a model on the combined training and validation set\n","SelectedLogRegModel = LogisticRegression(C=best_parameters).fit(X_trainval_scaled_dna, Y_trainval_dna)\n","\n","test_score = SelectedLogRegModel.score(X_test_scaled_dna, Y_test_dna)\n","PredictedOutput = SelectedLogRegModel.predict(X_test_scaled)\n","test_recall = recall_score(Y_test, PredictedOutput, pos_label=1)\n","fpr, tpr, thresholds = roc_curve(Y_test, PredictedOutput, pos_label=1)\n","test_auc = auc(fpr, tpr)\n","print(\"Best accuracy on validation set is:\", best_score)\n","print(\"Best parameter for regularization (C) is: \", best_parameters)\n","print(\"Test accuracy with best C parameter is\", test_score)        \n","print(\"Test recall with the best C parameter is\", test_recall)\n","print(\"Test AUC with the best C parameter is\", test_auc)\n","\n","m = 'Logistic Regression (w/ dropna)'\n","acc.append([m, test_score, test_recall, test_recall, fpr, tpr, thresholds])"]},{"cell_type":"markdown","metadata":{"_uuid":"9b30f505fa1febaa9b0577ef2943906046f77413"},"source":["In overall, dataset with imputation outperforms the one without imputation. For the later models, we use dataset without imputation."]},{"cell_type":"markdown","metadata":{"_uuid":"c3fcf0473df26fdea9ba51953aab1f53b2e522c5","colab_type":"text","id":"Gj3b-ssXScS2"},"source":["## SVM\n","C: Penalty parameter C of the error term. [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n","\n","gamma: kernel coefficient. [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n","\n","kernel: kernel type. ['rbf', 'linear', 'poly', 'sigmoid']"]},{"cell_type":"code","execution_count":23,"metadata":{"_uuid":"527bf4c3aaeb65eeb16f929c2c8c82ce4c2263c2","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{}]},"colab_type":"code","id":"Xp5EM__NScS2","outputId":"ac91ced2-9648-4248-8c62-6babfb401178"},"outputs":[],"source":["best_score = 0\n","\n","for c_paramter in [0.001, 0.01, 0.1, 1, 10, 100, 1000]: #iterate over the values we need to try for the parameter C\n","    for gamma_paramter in [0.001, 0.01, 0.1, 1, 10, 100, 1000]: #iterate over the values we need to try for the parameter gamma\n","        for k_parameter in ['rbf', 'linear', 'poly', 'sigmoid']: # iterate over the values we need to try for the kernel parameter\n","            svmModel = SVC(kernel=k_parameter, C=c_paramter, gamma=gamma_paramter) #define the model\n","            # perform cross-validation\n","            scores = cross_val_score(svmModel, X_trainval_scaled, Y_trainval, cv=kfolds, scoring='accuracy')\n","            # the training set will be split internally into training and cross validation\n","\n","            # compute mean cross-validation accuracy\n","            score = np.mean(scores)\n","            # if we got a better score, store the score and parameters\n","            if score > best_score:\n","                best_score = score #store the score \n","                best_parameter_c = c_paramter #store the parameter c\n","                best_parameter_gamma = gamma_paramter #store the parameter gamma\n","                best_parameter_k = k_parameter\n","            \n","\n","# rebuild a model with best parameters to get score \n","SelectedSVMmodel = SVC(C=best_parameter_c, gamma=best_parameter_gamma, kernel=best_parameter_k).fit(X_trainval_scaled, Y_trainval)\n","\n","test_score = SelectedSVMmodel.score(X_test_scaled, Y_test)\n","PredictedOutput = SelectedSVMmodel.predict(X_test_scaled)\n","test_recall = recall_score(Y_test, PredictedOutput, pos_label=1)\n","fpr, tpr, thresholds = roc_curve(Y_test, PredictedOutput, pos_label=1)\n","test_auc = auc(fpr, tpr)\n","print(\"Best accuracy on cross validation set is:\", best_score)\n","print(\"Best parameter for c is: \", best_parameter_c)\n","print(\"Best parameter for gamma is: \", best_parameter_gamma)\n","print(\"Best parameter for kernel is: \", best_parameter_k)\n","print(\"Test accuracy with the best parameters is\", test_score)\n","print(\"Test recall with the best parameters is\", test_recall)\n","print(\"Test recall with the best parameter is\", test_auc)\n","\n","m = 'SVM'\n","acc.append([m, test_score, test_recall, test_auc, fpr, tpr, thresholds])"]},{"cell_type":"markdown","metadata":{"_uuid":"2a111665a3aeefa0449d6e9b86efb45e14e5996d","colab_type":"text","id":"mYGAer5hScS5"},"source":["## Decision Tree"]},{"cell_type":"code","execution_count":24,"metadata":{"_uuid":"4c27de17e77f9b986e27d2090113bce38bd67fba","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{}]},"colab_type":"code","id":"jGI1Smg7ScS6","outputId":"86ea4ca6-b57f-47c0-fc4c-a958e1da8f95"},"outputs":[],"source":["best_score = 0\n","\n","for md in range(1, 9): # iterate different maximum depth values\n","    # train the model\n","    treeModel = DecisionTreeClassifier(random_state=0, max_depth=md, criterion='gini')\n","    # perform cross-validation\n","    scores = cross_val_score(treeModel, X_trainval_scaled, Y_trainval, cv=kfolds, scoring='accuracy')\n","    \n","    # compute mean cross-validation accuracy\n","    score = np.mean(scores)\n","    \n","    # if we got a better score, store the score and parameters\n","    if score > best_score:\n","        best_score = score\n","        best_parameter = md\n","\n","# Rebuild a model on the combined training and validation set        \n","SelectedDTModel = DecisionTreeClassifier(max_depth=best_parameter).fit(X_trainval_scaled, Y_trainval )\n","\n","test_score = SelectedDTModel.score(X_test_scaled, Y_test)\n","PredictedOutput = SelectedDTModel.predict(X_test_scaled)\n","test_recall = recall_score(Y_test, PredictedOutput, pos_label=1)\n","fpr, tpr, thresholds = roc_curve(Y_test, PredictedOutput, pos_label=1)\n","test_auc = auc(fpr, tpr)\n","print(\"Best accuracy on validation set is:\", best_score)\n","print(\"Best parameter for the maximum depth is: \", best_parameter)\n","print(\"Test accuracy with best parameter is \", test_score)\n","print(\"Test recall with best parameters is \", test_recall)\n","print(\"Test AUC with the best parameter is \", test_auc)\n","\n","m = 'Decision Tree'\n","acc.append([m, test_score, test_recall, test_auc, fpr, tpr, thresholds])"]},{"cell_type":"code","execution_count":25,"metadata":{"_uuid":"802da5f22fbe73ff4d4ff097408da95100fababe","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{},{}]},"colab_type":"code","id":"3k1LzTAOScS9","outputId":"c4d23b31-7cde-459d-c745-df64c9716cad"},"outputs":[],"source":["print(\"Feature importance: \")\n","np.array([X.columns.values.tolist(), list(SelectedDTModel.feature_importances_)]).T"]},{"cell_type":"code","execution_count":26,"metadata":{"_uuid":"9df711a59c1470af47f2c5a83f2e9cb11dcb00c7","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{}]},"colab_type":"code","id":"jAXEhs2gScS_","outputId":"8fccfeea-ec7f-4bad-9029-0b66b4aa09f7"},"outputs":[],"source":["from sklearn.tree import export_graphviz\n","import graphviz \n","dot_data=export_graphviz(SelectedDTModel, feature_names=X_trainval.columns.values.tolist(),out_file=None)\n","graph = graphviz.Source(dot_data)  \n","graph "]},{"cell_type":"markdown","metadata":{"_uuid":"20608c740de79f3ea76598be6c3e3e8fd158fd82","colab_type":"text","id":"ZkIF7600ScTD"},"source":["## Random Forest Classifier"]},{"cell_type":"code","execution_count":27,"metadata":{"_uuid":"0314f070def4da297b2b8712cea7727f6d5d8112","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{}]},"colab_type":"code","id":"zi0Ssns3ScTE","outputId":"e7adb6b8-ccfd-47b4-f65c-01848c1a0450"},"outputs":[],"source":["best_score = 0\n","\n","for M in range(2, 15, 2): # combines M trees\n","    for d in range(1, 9): # maximum number of features considered at each split\n","        for m in range(1, 9): # maximum depth of the tree\n","            # train the model\n","            # n_jobs(4) is the number of parallel computing\n","            forestModel = RandomForestClassifier(n_estimators=M, max_features=d, n_jobs=4,\n","                                          max_depth=m, random_state=0)\n","        \n","            # perform cross-validation\n","            scores = cross_val_score(forestModel, X_trainval_scaled, Y_trainval, cv=kfolds, scoring='accuracy')\n","\n","            # compute mean cross-validation accuracy\n","            score = np.mean(scores)\n","\n","            # if we got a better score, store the score and parameters\n","            if score > best_score:\n","                best_score = score\n","                best_M = M\n","                best_d = d\n","                best_m = m\n","\n","# Rebuild a model on the combined training and validation set        \n","SelectedRFModel = RandomForestClassifier(n_estimators=M, max_features=d,\n","                                          max_depth=m, random_state=0).fit(X_trainval_scaled, Y_trainval )\n","\n","PredictedOutput = SelectedRFModel.predict(X_test_scaled)\n","test_score = SelectedRFModel.score(X_test_scaled, Y_test)\n","test_recall = recall_score(Y_test, PredictedOutput, pos_label=1)\n","fpr, tpr, thresholds = roc_curve(Y_test, PredictedOutput, pos_label=1)\n","test_auc = auc(fpr, tpr)\n","print(\"Best accuracy on validation set is:\", best_score)\n","print(\"Best parameters of M, d, m are: \", best_M, best_d, best_m)\n","print(\"Test accuracy with the best parameters is\", test_score)\n","print(\"Test recall with the best parameters is:\", test_recall)\n","print(\"Test AUC with the best parameters is:\", test_auc)\n","\n","m = 'Random Forest'\n","acc.append([m, test_score, test_recall, test_auc, fpr, tpr, thresholds])"]},{"cell_type":"code","execution_count":28,"metadata":{"_uuid":"7264a60baa490343e92e743d43f635a18af9fa13","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{},{}]},"colab_type":"code","id":"Mcx6LmzcScTJ","outputId":"f7ba2e6f-1a5b-4495-a9b1-2a0973101259"},"outputs":[],"source":["print(\"Feature importance: \")\n","np.array([X.columns.values.tolist(), list(SelectedRFModel.feature_importances_)]).T"]},{"cell_type":"markdown","metadata":{"_uuid":"5defe4c299e6a47547b1d05a533c90aba26c0365","colab_type":"text","id":"w1vFrwcwScTO"},"source":["# RESULTS"]},{"cell_type":"code","execution_count":31,"metadata":{"_uuid":"567d27a76de89fd5c9feb715bfc0e58400872f7e"},"outputs":[],"source":["# Performance Metric for each model\n","result = pd.DataFrame(acc, columns=['Model', 'Accuracy', 'Recall', 'AUC', 'FPR', 'TPR', 'TH'])\n","result[['Model', 'Accuracy', 'Recall', 'AUC']]"]}],"metadata":{"anaconda-cloud":{},"colab":{"collapsed_sections":[],"default_view":{},"name":"FinalReport_Code.ipynb","provenance":[],"version":"0.3.2","views":{}},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":4}
